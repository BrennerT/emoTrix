\section{Schluss}
In diesem Kapitel werden zunächst Anwendungsszenarien vorgestellt, in denen die entwickelte App mit ihrer Architektur sinnvoll eingesetzt werden kann. Anschließend wird ein Fazit zur gesamten Studienarbeit und ein Ausblick auf weitere mögliche Schritte des Projekts geliefert.
\subsection{Anwendungsszenarien}
\subsectionauthor{Torben Brenner \& Lukas Seemann}
Im Folgenden wird die Frage beantwortet, für welche Zwecke die App emoTrix in Zukunft verwendet werden kann. \newline
Die Verwendung von Emotionserkennung über das Smartphone ermöglicht es, sehr einfach neue Studien in diesem Bereich durchzuführen. Durch das Verteilen einer einfachen Installationsdatei könnten Studienteilnehmer ohne großen Aufwand an einer Studie teilnehmen. Denkbar wären hierbei Szenarios, bei denen die Teilnehmer zum Beispiel zehn Minuten täglich einen Test durchführen sollen oder in denen sie durch eine bestimmte Auswahl von Sensoren dauerhaft analysiert werden. Damit wären Studien über den emotionalen Verlauf eines Arbeitstags möglich.\newline
Unsere Architektur eignet sich insbesondere für solche Fälle, da es möglich ist, eine beliebige Anzahl an Sensoren im Hintergrund arbeiten zu lassen und deren Ergebnisse zusammen zu führen.\newline 
Da die Emotion möglichst natürlich sein und nicht bewusst beispielsweise durch Grimassen bei der Gesichtserkennung vorgetäuscht werden sollen, wäre es sinnvoll, die App zu dem Zeitpunkt einzusetzen, wenn die Emotion hervorgerufen wird. Es muss also unmittelbar die erste Reaktion des Anwenders auf Reize von außen eingefangen werden. Hierbei ergibt sich eine mögliche Anwendung der App emoTrix. \newline
Die App kann dazu eingesetzt werden, um zu bestimmen, wie Leute auf verschiedenes Bild- oder Filmmaterial reagieren. Während der Anwender verschiedene Bilder oder Filme zum ersten Mal sieht, müssen verschiedene Emotionstests der App gestartet werden. Am Ende kann man über die Auswertung nachvollziehen, welche Emotion bei welchem Bildmaterial empfunden wurden. Beispielsweise kann der Anwender, während er auf die Bilder reagiert, mit dem GSR-Sensor verbunden sein. Gleichzeitig wird bei jedem neuen Bild direkt bei der Reaktion ein Bild aufgenommen oder bei einem Film zum Beispiel alle 10 Sekunden. Diese Bilder können dann von der App analysiert werden. Zusätzlich kann der Anwender gebeten werden, das Gesehene zu kommentieren. Diese Sprachaufnahmen können auch mit der App analysiert werden. So ist es möglich, eine möglichst genaues Ergebnis der Emotionsbestimmung zu erhalten. \newline
Mithilfe der App kann im Nachhinein eine Studie durchgeführt werden, die untersucht, mit welchen Emotionen Menschen auf Bilder oder Filme reagieren. Hieraus können wertvolle Informationen und Statistiken gewonnen werden, was Menschen generell erfreut, bekümmert oder verärgert. \newline
Ein weiterer Anwendungsfall der entwickelten Architektur ist die kommerzielle Nutzung. Gerade für Online Shops ist es interessant, welche Emotionen Kunden beim Betrachten unterschiedlicher Artikel empfinden. So könnten zum Beispiel Artikel, die Emotionen wie Ekel hervorrufen, gezielt ausgemacht werden und diese Erkenntnisse für zukünftige Artikel berücksichtigt werden. Ebenfalls die Analyse der Reaktion des Nutzers auf einen Werbespot ist für Marketingzwecke relevant. Eine Praxis, die bereits in Call Centern angewandt wird, ist die Analyse der Stimme, um festzustellen, wie der emotionale Zustand eines Anrufers ist. So können die Mitarbeiter im Zweifelsfall direkt deeskalierend mit dem/der Anrufer/-in sprechen.\newline
\subsection{Ausblick}
\subsectionauthor{Torben Brenner \& Lukas Seemann}
Da von den vorgestellten Erfassungsmöglichkeiten von biometrischen Daten bislang nur die Gesichtserkennung und die Hautwiderstand-Messung und damit Platz 1 und Platz 2 der Prioriserungsliste implementiert wurden, kann die App in Zukunft um weitere Emotionstest erweitert werden. Die hier vorgestellten Möglichkeiten können dafür als Vorlage dienen. Der nächste zu implentierende Emotionstest ist die Stimmerkennung. Danach folgt das Analysieren des Tippverhaltens und alternativ können im Anschluss daran auch noch die restlichen Erfassungsmöglichkeiten der Priorsierungsliste als Emotionstest umgesetzt werden. Neue Test können aufgrund der Architektur von emoTrix einfach integriert werden.\newline Außerdem wäre es von Vorteil, wenn diese Tests auch parallel zu anderen Tests durchgeführt werden können. So wäre zum Beispiel eine Anpassung des Kamera Sensors wünschenswert, die das Aufnehmen von Bildern automatisiert. Dadurch würden die Ergebnisse deutlich schwerer zu verfälschen sein.\newline
Ein Erweiterung der App um Emotionstest führt zu genaueren Ergebnissen, da der Decider so mehr Daten als Entscheidungsgrundlage zur Verfügung hat. Dies ist auf jeden Fall eine wünschenswerte Weiterentwicklung der Anwendung.\newline
Zusätzlich müssen mit der Zeit auch die Kausalitätsregeln verbessert werden. Im Speziellen könnte hier eine Erweiterung der Oberfläche stattfinden, in der Nutzer nicht nur analysiert werden, sondern auch die Analyseergebnisse in der Auswertung korrigieren. Hierzu könnte im Auswertungsbildschirm eine Meldung von falschen Analysen mit eingebaut werden, um kontinuierlich Nutzer Feedback zu sammeln. In einer ausgeweiteten Variante davon, könnte sogar ein neuronales Netz eingesetzt werden, um die Gewichtung von Indizien in Form der Kausalitätsregeln zu verbessern. Dabei würde das Training primär von den Nutzern durchgeführt.
\subsection{Fazit}
\subsectionauthor{Torben Brenner \& Lukas Seemann}
Das Ziel der Arbeit bestand in der Untersuchung von Möglichkeiten anhand von biometrischen Daten Emotionen zu ermitteln. Dabei wurden vor allem die Technologien priorisiert, die in Verbindung mit Smartphones genutzt werden können. In den Recherchen konnten viele Erfassungsarten detailliert betrachtet, analysiert und für die mobile Applikation ausgewählt werden. Basierend auf den Recherchen konnte ein Konzept für eine Architektur erstellt werden, die es ermöglicht, beliebige Sensoren einzubinden und deren Daten zu verarbeiten. Obwohl aufgrund von Zeitmangel nicht alle geplanten Emotionstests umgesetzt werden konnten, ermöglicht die Architektur eine einfache Erweiterung um zusätzliche Funktionalitäten. \newline
Außerdem wurde auch auf die Möglichkeit Wert gelegt, dass in Zukunft die Emotionsbestimmung durch das Anpassen und Hinzufügen von Kausalitätsregeln verbessert werden kann. Dadurch ist es möglich, die mobile Applikation an beliebige Anwendungsszenarien anzupassen. Hier könnte auch ein detaillierteres Wissen über den Zusammenhang zwischen Emotionen und biometrischen Merkmalen von Vorteil sein, da es damit möglich wäre, deutlich fundiertere Kausalitätsregeln zu definieren. Durch bessere Kausalitätsregeln können auch Emotionen präziser bestimmt werden.\newline
Der im Rahmen dieser Studienarbeit entwickelte Prototyp ist in der Lage, mithilfe der Erfassung von zwei biometrischen Merkmalen auf Emotionen zu schließen. Obwohl dadurch noch nicht vollkommen aussagekräftige Emotionsanalysen erstellt werden können, stellt der Prototyp mit seinen Funktionalitäten und seiner Architektur eine gute Basis für zukünftige Forschung in diesem Gebiet dar.