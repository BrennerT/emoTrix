\section{Schluss}
Hier werden wir darauf eingehen was erreicht wurde was nicht und weshalb nicht.
\subsection{Anwendungsszenarien}
\subsectionauthor{Lukas Seemann}
% Studien
% Belegung verschiedener Theorien für mögliche Emotionsindizien
Der im Rahmen dieser Studienarbeit entwickelte Prototyp ist in der Lage, mithilfe der Erfassung von biometrischen Daten auf Emotionen zu schließen. Nun stellt sich die Frage, für welche Anwendungsszenarien die App nützlich sein könnte. Dieser Abschnitt soll diese Frage beantworten. \newline \newline
Da die Emotion möglichst natürlich sein sollen und nicht bewusst vorgetäuscht beispielsweise durch Grimassen bei der Gesichtserkennung werden sollen, wäre es sinnvoll, die App zu dem Zeitpunkt einzusetzen, wenn die Emotion hervorgerufen wird. Es muss also unmittelbar die erste Reaktion des Anwenders auf Reize von außen eingefangen werden. Hierbei ergibt sich eine mögliche Anwendung der App emoTrix. \newline
Die App kann dazu eingesetzt werden, um zu bestimmen, wie Leute auf verschiedenes Bild- oder Filmmaterial reagieren. Während der Anwender verschiedene Bilder oder Filme zum ersten Mal sieht, müssen verschiedene Emotionstests der App gestartet werden. Am Ende kann man über die Auswertung nachvollziehen, welche Emotion bei welchem Bildmaterial empfunden wurden. Beispielsweise kann der Anwender, während er auf die Bilder reagiert, mit dem GSR-Sensor verbunden sein. Gleichzeitig wird bei jedem neuen Bild direkt bei der Reaktion ein Bild aufgenommen oder bei einem Film zum Beispiel alle 10 Sekunden. Diese Bilder können dann von der App analysiert werden. Zusätzlich kann der Anwender gebeten werden, das Gesehene zu kommentieren. Diese Sprachaufnahmen können auch mit der App analysiert werden. So ist es möglich, eine möglichst genaues Ergebnis der Emotionsbestimmung zu erhalten. \newline
Mithilfe der App kann im Nachhinein verglichen werden, mit welchen Emotionen Menschen auf Bilder oder Filme reagieren. Hieraus können wertvolle Informationen und Statistiken gewonnen werden, was Menschen generell erfreut, bekümmert oder verärgert. Natürlich muss hierfür auch die Datenschutz-Frage geklärt werden, da solche biometrische Daten ohne Genehmigung des Probanden nicht einfach veröffentlich werden dürfen.
\textbf{TORBEN: du kannst gerne noch ein weiteres Anwendungsszenario ergänzen}
\subsection{Fazit}

\subsection{Ausblick}
\subsectionauthor{Torben Brenner \& Lukas Seemann}
Da von den vorgestellten Erfassungsmöglichkeiten von biometrischen Daten bislang nur die Gesichtserkennung und die Hautleitwiderstand-Messung und damit Platz 1 und Platz 2 der Prioriserungsliste implementiert wurden, kann die App in Zukunft um weitere Emotionstest erweitert werden. Die hier vorgestellten Möglichkeiten können dafür als Vorlage dienen. Der nächste zu implentierende Emotionstest ist die Stimmerkennung. Danach folgt das Analysieren des Tippverhaltens und alternativ können im Anschluss daran auch noch die restlichen Erfassungsmöglichkeiten der Priorsierungsliste als Emotionstest umgesetzt werden. Neue Test können aufgrund der Architektur von emoTrix einfach integriert werden. \newline
Ein Erweiterung der App um Emotionstest führt zu genaueren Ergebnissen, da der Decider so mehr Daten als Entscheidungsgrundlage zur Verfügung hat. Dies ist auf jeden Fall eine wünschenswerte Weiterentwicklung der Anwendung.\newline
Zusärtlich müssen mit der Zeit auch die Kausalitätsregeln verbessert werden. \textbf{TORBEN: schreib was über deine KI Idee ;)} 
% Sollte mit KI Learning verbessert werden können 