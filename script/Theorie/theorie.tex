\section{Biometrie und Emotionen}
In diesem Kapitel werden theoretische Grundlagen zu Biometrie und Emotionen dargestellt, die wichtig für das weitere Verständnis der Studienarbeit sind. Außerdem werden verschiedene Möglichkeiten vorgestellt, wie mithilfe von Smartphones und externen Sensoren biometrische Daten erfasst werden können.
\subsection{Biometrie und biometrische Merkmale}
\subsectionauthor{Torben Brenner}
\label{section:Biometrie}
Bei der Biometrie handelt es sich um die Wissenschaft, die sich mit der Vermessung von biologischen Merkmalen beschäftigt \footcite[Vgl.][]{Sea18}. Dabei werden insbesondere in der Informationstechnologie Technologien zur Messung und Analyse von körperlichen Merkmalen untersucht.\newline
Diese Merkmale werden auch als biometrische Merkmale bezeichnet. Dabei wird unterschieden zwischen den verhaltensbasierten und den physiologischen Merkmalen\footcite[Vgl. ][]{Sas06}. Erstere zeichnen sich dadurch aus, dass eine Person aktiv eine Handlung ausführen muss, um das Merkmal zu zeigen, während die physiologischen Merkmale dauerhaft von einer Person getragen werden. Ein Beispiel für ein verhaltensbasiertes Merkmal ist die Gangart eines Menschen, die sogar zur Authentifizierung verwendet werden kann\footcite[Vgl. ][]{Cla09}. Ein bekanntes physiologisches Merkmal ist der Fingerabdruck einer Person.\newline
Ein häufiger Einsatzzweck der Biometrie ist die Authentifizierung eines Nutzers gegenüber einem System. Da sich nicht alle Merkmale für eine solche Identifikation eignen, müssen verschiedene Faktoren bei der Auswahl der Merkmale betrachtet werden. Jain, Ross und Prabhakar\footcite[Vgl. ][S.2]{Akj04} nennen zum Beispiel folgende Faktoren: 
\begin{itemize}
	\item \textbf{Universalität}: Jeder Mensch sollte dieses Merkmal besitzen.
	\item \textbf{Unterscheidbarkeit}: Das Merkmal soll sich so stark wie möglich zwischen zwei Personen unterscheiden.
	\item \textbf{Permanenz}: Das Merkmal sollte sich über die Zeit betrachtet nicht oder nur in geringem Maße ändern.
	\item \textbf{Erfassbarkeit}: Das Merkmal sollte möglichst einfach dauerhaft erfasst werden können.
	\item \textbf{Performanz}: Beschäftigt sich mit der Frage, mit welchem Zeitaufwand und mit welcher Geschwindigkeit ein Merkmal gemessen werden kann. 
	\item \textbf{Akzeptanz}: Beschäftigt sich mit der Frage, in wie weit Nutzer mit der Messung eines Merkmals einverstanden sind. 
	\item \textbf{Umgehbarkeit}: Beschäftigt sich mit der Frage, in wie weit ein Nutzer dem System vortäuschen kann, dass er ein anderer Nutzer ist.
\end{itemize}
Die ersten vier Faktoren beschäftigen sich im Allgemeinen mit der Eignung eines Merkmals für die Authentifizierung, während sich die letzten Faktoren mit der Eignung eines biometrischen Systems für eine Aufgabe beschäftigen. Da sich unsere Fragestellung aber nicht auf die Authentifizierung eines Nutzers gegenüber eines informationstechnischen Systems bezieht, sondern sich mit der Auswertung der erfassten Daten für die Erkennung von Emotionen beschäftigt, ist der Faktor der \textit{Unterscheidbarkeit} zu vernachlässigen. Die restlichen Faktoren werden aber später für die einzelnen biometrischen Merkmale untersucht wobei sich die Faktoren \textit{Performanz, Akzeptanz und Umgehbarkeit} auf die Messung mit Smartphones beziehen.
\subsection{Emotionen}
In diesem Abschnitt wird anhand von wissenschaftflichen Quellen belegt, was genau unter einer Emotion verstanden wird. Außerdem wird thematisiert, wie Emotionen gemessen werden können.
\subsubsection{Definition}
\subsubsectionauthor{Torben Brenner}
Da wir uns in dieser Arbeit mit der Erkennung von Emotionen beschäftigen, ist es notwendig, dass wir den Begriff der Emotion definieren. Das Problem an dem Begriff der Emotion ist, dass diese ein hypothetisches Konstrukt ist, welches sich aus der physiologischen Erregung, dem motorischen Ausdruck, Handlungstendenzen und einem subjektiven Gefühl zusammensetzt. \footcite[Vgl.][S.166 Abschnitt Emotion]{Kla02}\newline
Als Beispiel nennt Klaus Scherer hier das plötzliche Auftreten eines Mannes mit einem Blut verschmierten Messer beim Sonntagsspaziergang. Er beschreibt daraufhin, welche Aspekte in diesem Szenario eine Rolle spielen. So kann zum einen eine physiologische Reaktion gemessen werden, in Form eines erhöhten Herzschlages. Außerdem wird eine motorische Reaktion stattfinden, zum Beispiel ein weit aufgerissener Mund und weit aufgerissene Augen. Die Handlungstendenz wäre in seinem Beispiel der plötzliche Drang wegzulaufen und bei der späteren Befragung zu dieser Situation könnte eine Person sagen, dass sie Furcht gefühlt hat.\newline
Scherer\footcite{Kla05} definiert eine Emotion im Zusammenhang mit dem \textit{component process model} als eine Abfolge von zusammenhängenden, synchronisierten Veränderungen der Zustände von allen oder den meisten der fünf Subsysteme des Organismus als Reaktion auf die Verarbeitung eines externen oder internen Stimulus-Ereignis, das relevant für den Organismus ist\footcite[Vgl. ][S.697 Z.32ff Übersetzung ins Deutsche]{Kla05}. In einer Tabelle (siehe Abbildung 1) zeigt Scherer die Verbindung zwischen den organischen Subsystemen und den Komponenten und Funktionen einer Emotion. 
\begin{figure}[h]
	\centering
	\includegraphics[width=15cm]{Bilder/Relationships-between-organismic-subsystems.png}
	\label{img:Emotion}
	\caption[Relationships between organismic subsystems and the functions and components of
	emotion - Klaus R. Scherer]{Relationships between organismic subsystems and the functions and components of
		emotion - Klaus R. Scherer\footnotemark}
\end{figure}%
\footcitetext[Vgl.][S.698 Table 1]{Kla05}
\newline
Anhand dieser Tabelle lässt sich eine Unterscheidung zwischen dem Begriff Gefühl und Emotion durchführen. Der Unterschied ist, dass ein Gefühl (\textit{subjective feeling component}) eine einzelne Komponente der Emotion ist, welche erst in Verbindung mit den anderen Emotionskomponenten zu einer Emotion führt. Andere Komponenten sind zum Beispiel die Bewertung der Situation (\textit{Cognitive component}) oder körperliche Symptome (\textit{Neurophysiological component}). Der Gesichtsausdruck und die Stimme werden auch als eigene Komponenten (\textit{Motor expression component}) gewertet. \newline \newline
\newline
\subsubsection{Eingrenzung der zu messenden Emotionen}
\subsubsectionauthor{Torben Brenner}
Bevor geklärt werden kann, wie Emotionen gemessen werden können, ist es notwendig sich auf eine Menge von Emotionen zu einigen. Da es viele unterschiedliche Emotionen gibt, laut Hokuma\footcite[Vgl.][Absch. 1]{Hok17} sind es 34.000 unterschiedliche Emotionen, stellt sich die Einteilung als äußerst schwer da. Einen Versuch, die Emotionen einzuteilen, hat bereits Robert Plutchick unternommen. Dieser ist zu dem Schluss gekommen, dass es acht primäre Emotionen gibt: Freude, Traurigkeit, Akzeptanz, Ekel, Angst, Wut, Überraschung und Erwartung. Um den Zusammenhang zwischen diesen und einigen anderen Emotionen darzustellen, wurde das Rad der Emotionen entwickelt (siehe Abbildung 2).\newline
\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{Bilder/wheel-of-emotions.png}
	\caption[Rad der Emotionen - Robert Plutchick]{Rad der Emotionen - Robert Plutchick\footnotemark}
\end{figure}%
\footcitetext[Vgl.][]{Hok17}
\newline
Das Rad stellt die primären Emotionen dabei in Relation, wobei die Kombinationen zwischen zwei Emotionen im Raum zwischen diesen steht und Emotionen, die gegensätzlich wirken, zum Beispiel Traurigkeit und Freude, jeweils auch gegenüberliegend auf dem Rad sind. Außerdem wird die Stärke einer Emotion durch deren Nähe zum Zentrum des Rads gekennzeichnet, zum Beispiel Wut zu toben \footcite[Vgl.][Absch. Elements of the Wheel]{Hok17}.\newline
Somit stellt das Rad der Emotionen eine Eingrenzung der vielen unterschiedlichen Emotionen in mehrere Kategorien dar. Außerdem lässt sich anhand des Rades der Zusammenhang und die Intensität verschiedener Emotionen besser verstehen. 
\subsubsection{Wie lassen sich Emotionen messen?}
\subsubsectionauthor{Torben Brenner}
Nachdem nun geklärt ist, wie eine Emotion aufgebaut ist, müssen wir uns die Frage stellen, wie es möglich ist, eine Emotion zu messen. Der naheliegendste Ansatz ist, zu versuchen, die einzelnen Emotionskomponenten messbar zu machen. Dass dies nicht so einfach umzusetzen ist, zeigt die Betrachtung der kognitiven Emotionskomponente. Diese steht im direkten Zusammenhang mit dem zentralen Nervensystem (siehe Abbildung 1). Eine Messung der Veränderungen in diesem System ist äußerst kompliziert und insbesondere in unserem Anwendungsfall nicht möglich. Dafür lassen sich aber zum Beispiel köperliche Symptome, wie zum Beispiel der Puls, messen und auswerten.\newline
Ein weiterer Ansatz, Emotionen zu messen, ist das von Scherer entwickelte \textit{Geneva Emotion Wheel}. Das \textit{Geneva Emotion Wheel} baut auf dem Ansatz auf, die Emotionen anhand verschiedener Dimensionen zu bestimmen. In einem Prototyp für das \textit{Geneva Emotion Wheel} (zu sehen in Abbildung 3) werden die beiden Dimensionen \textit{arousal} und \textit{valence} betrachtet.
\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{Bilder/Geneva-Emotion-Wheel.png}
	\label{img:Geneva}
	\caption[Prototype version of the Geneva Emotion Wheel - Klaus R. Scherer]{Prototype version of the Geneva Emotion Wheel - Klaus R. Scherer\footnotemark}
\end{figure}%
\footcitetext[Vgl.][S.723 Figure 2]{Kla05}
\newline
Die erste Dimension bezeichnet, wie stark die Erregung eines Individuums ausgeprägt ist in einer Situation. Die zweite Dimension gibt an, wie unwohl sich ein Individuum in einer Situation fühlt. Beide Dimensionen haben gemeinsam, dass sie durch die Befragung eines Individuums ermittelt werden müssen. 
\subsection{Umgang mit biometrischen Daten}
\subsectionauthor{Torben Brenner}
Eine Problematik, mit der wir uns in dieser Arbeit beschäftigen müssen, ist der Umstand, dass biometrische Daten nicht immer einen direkten Schluss auf eine Emotion zulassen. So lässt ein hochfrequenter Puls keinen direkten Schluss auf die Emotion zu, die ein Individuum gerade empfindet. Er kann maximal ein Indiz für verschiedene Emotionen sein, zum Beispiel Wut oder Angst. Um mit diesem Umstand umzugehen, benötigen wir zwei neue Begriffe, die im Folgenden genauer erläutert werden. 
\subsubsection{Indiz}
Ein Indiz ist im allgemeinen Sprachgebrauch ein Anzeichen für einen Umstand, an dem sich ein Zustand oder eine Entwicklung absehen lässt\footcite[Vgl.][]{Dud18}. In unserer Arbeit wollen wir die Daten, welche wir mit Hilfe der Sensoren erfassen, dazu nutzen, Indizien für die aktuell empfundene Emotion zu ermitteln. Im Zusammenhang mit dem \textit{component process model} gesehen, lässt sich ein Indiz als ein Anzeichen sehen, wie eine bestimmte Emotionskomponente zum aktuellen Zeitpunkt zu bewerten ist. Ein Beispiel für ein Indiz der \textit{neurophysiologischen Komponente} wäre der Puls. Mit den Daten der Sensoren können wir nur sagen, wie oft neues Blut durch die Atterien gepumpt wurde. Erst durch die Messung der Daten in einem bestimmten Zeitraum, kann der Puls richtig gemessen werden und bestimmt werden, ob dieser erhöht ist oder nicht.
\subsubsection{Kausalität}
Als Kausalität wird im Allgemeinen der Zusammenhang zwischen Ursache und Wirkung verstanden. In der Physik ist die Kausalität ein grundlegendes Prinzip, welches besagt, ``daß in der Natur nichts ohne Grund passiert, d.h. zu jedem Ereignis (Wirkung) ein anderes (Ursache) existiert, das a) in seiner Vergangenheit liegt und b) zwingende Voraussetzung für das Eintreten der Wirkung ist''\footcite{Sav18}.\newline
Ein Werkzeug, um kausale Zusammenhänge darzustellen, ist in der Literatur der kausale Graph (im englischen \textit{directed acyclic graph}).
\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{Bilder/dag.png}
	\caption[Fiktives Beispiel eines DAGs]{Fiktives Beispiel eines DAGs\footnotemark}
\end{figure}
\footcite[Vgl.][Kausale Graphen - DAGs]{Tho11}
Die Grafik (siehe Abbildung 4) zeigt ein fiktives Beispiel für einen kausalen Graphen. In diesem Beispiel von Thoemmes wird dargestellt, dass Bindungsstil, Geschlecht, Stressoren und Gene Einfluss auf Depressionen haben. Wichtig ist, dass alle Annahmen, die in einem solchen Graph gemacht werden, theoretisch begründet werden müssen. Ist dies nicht der Fall, dürfen sie kritisiert und infrage gestellt werden \footcite[Vgl. ][S.3 Kausale Graphen - DAGs]{Tho11}.\newline
In dieser Arbeit werden wir ebenfalls versuchen, kausale Zusammenhänge zwischen Reaktionen des Körpers und den gerade empfundenen Emotionen zu ermitteln. Dabei ist für uns das Eintreten einer Kausalität an Indizien gebunden. So könnte ein erhöhter Puls ein Anzeichen für Angst sein. Damit würde, wenn der erhöhte Puls als Indiz auftritt, über den kausalen Zusammenhang gefolgert werden, dass es wahrscheinlicher ist, dass die Emotion Angst empfunden wird. 
\subsection{Emotionsindizien}
\subsectionauthor{Torben Brenner}
\label{section:Emotionsindizien}
Dieser Abschnitt beschäftigt sich mit der Frage, welche biometrischen Merkmale existieren und inwiefern sie sich zur Bestimmung von Emotionen eignen. Daten, die sich zur Bestimmung von Emotionen eignen, nennen wir Emotionsindizien, da sie einen Hinweis auf die empfundenen Emotionen einer Person liefern.
\subsubsection{Puls}
\subsubsectionauthor{Torben Brenner}
% Was verstehen wir unter dem Begriff Puls
In diesem Abschnitt beschäftigen wir uns mit dem Puls als ein Indiz für verschiedene Emotionen. Hierbei wird der Puls als der biologische Puls gesehen, das heißt ``die in Abhängigkeit vom Herzrhythmus (Herzmechanik) erfolgende Schwankung von Blutstrom, Blutdruck oder Blutvolumen im Blutkreislaufsystem (Blutgefäßsystem, Blutkreislauf)''\footcite{Spe18}. Neben dieser Definition wird im Lexikon der Biologie auch folgende Definition genannt: ``die vom Herzschlag bewirkte, rhythmisch auftretende Druckwelle (Pulsschlag) in den Arterien''\footcite{Spe18}, welche den Puls als arteriellen Puls definiert. \newline
% Wie wird der Puls gemesen? Ruhepuls nicht Ruhepuls(Sphygmologie)
Es gibt mehrere Möglichkeiten, den Puls zu messen. Die häufigste Methode, welche auch in Erste-Hilfe-Kursen gelehrt wird, ist die Messung des Pulses an der Arterie. Das Grundprinzip ist dabei, dass die vom Herzschlag verursachte Druckwelle an der Arterie für Menschen spürbar ist und somit dort mitgezählt werden kann.\newline
% Wie lässt sich der Puls als Biometrisches Merkmal einordnen?
Der Puls ist in der Biometrie als ein physiologisches Merkmal zu sehen. Eine Person muss keine speziellen Handlungen durchführen, um einen Puls zu haben. Der Aspekt der \textit{Universalität} ist bei diesem Merkmal gegeben, da jeder Mensch einen Puls besitzt. Eine Erfassung des Pulses ist quasi jeder Zeit möglich, zumindest für Menschen. Ein Smartphone bietet aber auch mehrere Möglichkeiten, den Puls zu messen, die später in dem Abschnitt ``Erfassung der biometrischen Daten'' weiter erläutert werden. Der Aspekt der Permanenz ist nicht vollständig gegeben. Der Puls bewegt sich zwar standardmäßig in einem bestimmten Wertebereich, ist aber abhängig von Alter und körperlicher Verfassung einer Person.\newline
% In wie fern kann der Puls als Indiz verwendet werden?
Als Emotionsindiz kann der Puls unterstützend wirken, da dieser eine physiologische Auswirkung von verschiedenen Emotionen sein kann. Dennoch ist er kein alleiniges Merkmal für eine bestimmte Emotion, da sowohl Freude als auch Angst einen erhöhten Puls zur Folge haben können.
\subsubsection{Hautleitfähigkeit/Hautwiderstand}
\subsubsectionauthor{Lukas Seemann}
Die menschliche Haut verfügt über \glqq \textit{aktive als auch passive elektrische Eigenschaften, die sich auf Strukturen und Fuktionen der Haut und der in ihr enthaltenen Organe zurückführen lässt.}\grqq{}\footcite[][S. 2]{Bou88} Diese elektrischen Phänomene der Haut sind in wissenschaftlichen Kreisen unter dem Sammelbegriff elektrodermale Aktivität (kurz EDA) bekannt. \footcite[Vgl.][S. 2]{Bou88}
Eine elektrodermale Aktivität, die sich sehr gut als Indikator für Emotionen eignet, ist die Hautleitfähigkeit. Hierzu wird mit einer externen Stromquelle mit geringer Spannung gemessen, wie gut die Haut eines Probanden diesen Strom leitet. \footcite[Vgl. ][S.77]{Moe07} Häufig wird anstatt der Hautleitfähigkeit auch der Hautwiderstand gemessen. Diese beiden Indizien stehen in einer negativ proportionalen Beziehung. Das bedeutet, je höher der Widerstand der Haut ist, desto niedriger ist die Leitfähigkeit und umgekehrt. Letzten Endes sagen beide Indizien dasselbe aus, unterscheiden sich aber in der Betrachtungsrichtung. \footcite[Vgl. ][S. 28]{Die06} \newline
Die Hautleitfähigkeit wird anhand der Menge von Schweiß an den Ausgängen der Schweißdrüßen bestimmt, die sich über den gesamten Körper veteilen. Je mehr Schweiß, der elektrisch sehr gut leitend ist, sich auf der Haut befindet, umso größer ist die Hautleitfähigkeit. Am besten eignen sich  Stellen, an denen die Schweißdrüsen sehr dicht angeordnet sind und die somit sehr schweißsensibel sind. Dies ist zum Beispiel an den Handinnenflächen beziehungsweise Fingerinnenseiten der Fall, die sich deshalb sehr gut für solche Messungen eignen. \footcite[Vgl. ][S.77]{Moe07} 
\begin{figure}[h]
	\centering
	\includegraphics[width=16cm]{Bilder/symp.png}
	\caption[Reaktion des Körpers auf Stress und Entspannung]{Reaktion des Körpers auf Stress und Entspannung\footnotemark}
\end{figure}%
\footcitetext[][S. 200]{Dil13}
\newline
\glqq \textit{Die Aktivation beschreibt das Ausmaß der physiologischen Aktiviertheit oder Wachheit eines Menschen}\grqq{}\footcite[][S. 28]{Die06}. Unter Aktivitation versteht man bei Menschen generell jede Art von emotionaler Erregung. Hierzu zählen unter anderem Wut, Aufregung, Schreckmomente oder auch extreme Freude. In Abbildung 5 ist die Reaktion des Körpers auf Stress (darausfolgend auch Aktivation) und auf Entspannung dargestellt. Die Schweißproduktion wird über das unwillkürliche Nervensystem gesteuert. Dieses besteht aus Sympathikus, der für die Bereitstellung von Energie und Arbeitsleistung zuständig ist, und dem Parasympathikus, der zur Erholung und Wiederherstellung von Körperfunktionen dient. \footcite[Vgl. ][S. 5]{Lie13} \newline Bei Stress oder Aufregung wird der Sympathikus aktiviert, was eine verstärkte Schweißproduktion und somit auch eine erhöhte Hautleitfähigkeit hervorruft. Außerdem wird die Herz- und Atemfrequenz erhöht und der Rhythmus dieser ist unregelmäßig. Die Reaktion auf ein Ereignis, das emotionale Erregung hervorruft, lässt sich meistens innerhalb von einer bis vier Sekunden anhand der Änderung der Hautleitfähigkeit feststellen. \footcite[Vgl.][S. 130f]{Sch14} \newline 
Bei Entspannung hingegen wird der Parasympathikus aktiviert, was zu einer verminderten Aktivität der Schweißdrüßen führt. Die Hautleitfähigkeit sinkt somit auch. Des Weiteren werden Herz- und Atem verlangsamt und gelangen wieder in einen normalen Rhythmus. \newline
Die Hautleitfähigkeit erfüllt bis auf die \textit{Unterscheidbarkeit} und die \textit{Umgehbarkeit} alle Faktoren, die im Kapitel \textit{Biometrie und biometrische Merkmale} aufgezählt wurden. Das Fehlen der \textit{Unterscheidbarkeit} und \textit{Umgehbarkeit} begründet sich dadurch, dass die Hautleitfähigkeit nicht eindeutig einem Menschen zuordenbar ist, sodass es sicherlich mehrere Menschen gibt, die in verschiedenen Situationen dieselbe Hautleitfähigkeit aufweisen. Natürlich unterscheiden sich Menschen in ihrem Grundniveau der Hautleitfähigkeit. So gibt es Menschen, die generell eine hohe Hautleitfähigkeit im entspannten Zustand haben, wohingegen es genauso Menschen mit generell niedriger Hautleitfähigkeit gibt. Dies reicht aber nicht aus, dass ein Mensch anhand dieser Werte eindeutig identifziert werden kann. \newline
Der Vorteil der Messung der Hautleitfähigkeit ist, dass diese unwillkürlich gesteuert wird und somit keine willentliche Mitarbeit des Probanden erfoderlich ist. Da die Aktivierung des Sympathikus automatisch geschieht, kann der Proband die Messung nicht verfälschen. \newline
Ein Nachteil des Verfahren ist, dass die Hautleitfähigkeit nur Rückschlüsse auf den Grad der Aktiviation zulässt, jedoch nicht gesagt werden kann, ob es sich um positive oder negative Reaktionen handelt. Die Wut über ein Ereignis würde zum selben Ergebnis führen, wie die übermäßige Freude über ein Ereignis. Aus diesem Grund müssen zur genauen Emotionsbestimmung weitere Indizien herangezogen werden. \footcite[Vgl. ][S.77]{Moe07}
\subsubsection{Mimik}
\subsubsectionauthor{Torben Brenner}
% Was bezeichnet der Gesichtsausdruck
Der Begriff Mimik bezeichnet Bewegungen der Gesichtsmuskulatur mit dem Ziel, eine Emotion auszudrücken. Dass nicht jede Gesichtsregung automatisch auch als Mimik gewertet werden kann, sieht man beispielsweise beim Kauen \footcite[Vgl. ][Mimik: Eine kurze Definition]{Kar18}.\newline
% In wiefern kann sie als biometrisches Merkmal gewertet werden
Der Vorteil der Mimik als Emotionsindiz ist, dass sie als eines der wenigen Indizien für direkte Aussagen zu den Emotionen gewählt werden kann. So ist es dem Menschen zum Beispiel möglich, alleine durch Beobachtung einer anderen Person Vermutungen anzustellen, welche Emotionen diese gerade empfindet\footcite[Vgl. ][Die sieben Grundemotionen, Absatz 1]{Kar18}. Eine Untersuchung, die diese Aussage zusätzlich unterstützt, ist der FEEL-Test\footcite[][]{Kes02}. FEEL steht für Facial Expressed Emotion Labeling und ist ein Computerprogramm, das auf den Arbeiten von Ekman\footcite{Ekm92} aufbaut. Bei dem Test werden den Probanden Bilder gezeigt, die jeweils eine von sechs Basisemotionen wiederspiegeln. Der Proband soll daraufhin versuchen, die Emotionen zu erkennen, wobei im Ergebnis die Richtigkeit der Antwort und die Antwortzeit betrachtet werden. Ziel des Tests war es ``objektiv
und reliabel die Fähigkeit eines Probanden erfassen, sechs mimisch kodierte Basisemotionen zu erkennen (Freude, Trauer, Ekel, Angst, Überraschung und Ärger)''\footcite[siehe. ][S.5 Z.11ff]{Kes02}. In einer Pilotstudie mit 77 Teilnehmern konnten die Probanden unterschiedlich gut die verschiedenen Emotionen erkennen: ``(Trauer 
70\%, Angst 71\%, Ekel 80\%, Überraschung 84\%, Freude 87\% und Ärger 94\%)''\footcite[siehe. ][S.9 Z.9f]{Kes02}.\newline
Die Ergebnisse der Studie zeigen, dass Menschen aus der Mimik einen Schluss auf eine Emotion ziehen können. Im Verlauf der Arbeit werden wir untersuchen, ob es Möglichkeiten gibt, mit der Smartphonekamera ebenfalls ein solches Ergebnis zu erzielen oder dieses sogar übertreffen zu können. 
\subsubsection{Tippverhalten}
\subsubsectionauthor{Torben Brenner}
Unter dem Tippverhalten wird die individuelle Art einer Person verstanden, wie sie auf virtuellen oder realen Tastaturen tippt. Dabei wird unter anderem der Eingaberhythmus als Erkennungsmerkmal betrachtet\footcite[Vgl. ][Allgemein Abs. 1]{Bio18b}. Die Erkennungsgenauigkeit, und damit auch die Sicherheit des Verfahrens, ist dabei von der Frequenz der abgefragten Werte und der eingestellten minimalsten Ähnlichkeit abhängig. Bei diesem biometrischen Merkmal handelt es sich um ein verhaltensorientiertes Merkmal. Erfassbar ist dieses Merkmal immer, wenn der Nutzer einen vorgegebenen Text eingeben muss und für diesen ein Vergleichsprofil vorhanden ist. Dies kann zum Beispiel auch zur zusätzlichen Prüfung bei der Passworteingabe verwendet werden.\newline
Es gibt wenige Arbeiten, die sich mit der Verbindung von Emotionen und dem Tippverhalten beschäftigen. Eine dieser wenigen Arbeiten ist von Trojahn, Arndt, Weinmann und Ortmeier. Diese stellten bezüglich dieses Themas fünf Thesen auf und prüften diese innerhalb ihrer Arbeit\footcite[Vgl. ][S.32 2.3 Hypotheses]{Tro13}. Drei dieser Hypothesen beziehen sich dabei direkt auf die Verbindung zwischen Tippverhalten und Emotionen, weshalb sie hier genannt werden\footcite[siehe ][S.33 Z.8-13 Übersetzung]{Tro13}:
\begin{itemize}
	\item \textbf{H3:} Je langsamer die Tippgeschwindigkeit, desto negativer werden Emotionen wahrgenommen
	\item \textbf{H4:} Je höher die Tippfehlerrate, desto negativer werden Emotionen wahrgenommen
	\item \textbf{H5:} Je höher der Fingerdruck, desto negativer werden Emotionen wahrgenommen
\end{itemize}
Um die Hypothesen zu prüfen, führten sie eine Studie mit zwei Samsung Galaxy Nexus Smartphones aus, bei der es die Aufgabe der Probanden war, mit Hilfe des Smartphones einen Text einzutippen. Dabei wurden den Probanden unterschiedliche Zeitgrenzen gegeben, um unterschiedliche Ebenen von Stress zu repräsentieren. Nachdem der Test durchgeführt war, sollten die Probanden noch einen Fragetext zu ihren empfundenen Emotionen beantworten\footcite[Vgl. ][S.33 3.1 Study Object and Study Task]{Tro13}. Durch ihre Studie konnten sie zeigen, dass Emotionen durch Tastendrücke beschrieben werden können. In diesem Zusammenhang wurden die Hypothesen 3 und 4 bestätigt, aber Hypothese 5 widerlegt\footcite[Vgl. ][S.35 5.1 Summary]{Tro13}.\newline
Durch diese Studie wurde gezeigt, dass das Tippverhalten ebenfalls als Emotionsindiz gewertet werden, weshalb es auch weiter untersucht werden soll.
\subsubsection{Gangart}
% Was ist die Gangart
Wie bereits im Abschnitt Biometrie und biometrische Merkmale (siehe S.\pageref{section:Biometrie}) erläutert, ist auch die Gangart eines Menschen ein biometrisches Merkmal. Die Gangerkennung setzt dabei darauf, ``dass jeder Mensch eine relativ spezifische Gangart besitzt, an der er unter Zuhilfenahme anthroprometrischer Maße wie Beinlänge und Bein Form nahezu eindeutig erkannt werden kann''\footcite[siehe ][Abschnitt Allgemein Abs.2 Z.2]{Bio18}. Dadurch entstehen beim Gehen verschiedene sich wiederholende Muster, die sich mit Hilfe von Sensoren erkennen lassen. So existieren mehrere Merkmale, die sich dazu eignen den menschlichen Gang zuerkennen, hier sei zum Beispiel die Schrittweite oder die Schrittzeit genannt.\newline
Verschiedene wissenschaftliche Quellen treffen die Aussage, dass sich Emotionen auch auf die Bewegung einer Person auswirken können. So stellen Walk \& Homan in ihrer Arbeit folgende Theorie auf.
\begin{quote}
	``Although emotion may be expressed in the face, it can also be expressed in the voice and in body movement. People jump with joy or cringe with fear.''\footcite[siehe ][S.437 Z.20-23]{Wal84}
\end{quote}
In ihrer Arbeit haben sie ein Experiment mit 24 Studenten durchgeführt, denen sie Videosequenzen vorgespielt haben, in denen zwei verschiedene Schauspielerinnen verschiedene körperliche und emotionale Zustände dargestellt haben. Die Studenten hatten in der ersten Phase des Experiments die Aufgabe, die gesehenen Videosequenzen zu beschreiben. In der zweiten Phase, in der den Studenten die Aufnahme erneut gezeigt wurde, hatten diese die Aufgabe, einzuschätzen, wie viele verschiedene Personen sie in dem Video gesehen haben und welches Geschlecht diese haben\footcite[Vgl. ][S.437+438 Method]{Wal84}. Als ein Ergebnis dieses Experiments stellten die Autoren in einer Tabelle (siehe Abbildung 6) ihre Ergebnisse mit denen von Ekman\footcite{Ekm92} in Vergleich. 
\begin{figure}[h]
	\centering
	\includegraphics[width=16cm]{Bilder/Gangerkennung-Emotion-Vgl.png}
	\caption[Event Study Compared with Studies of Facial Expression of Motion (Values in Percentages)]{Event Study Compared with Studies of Facial Expression of Motion (Values in Percentages)\footnotemark}
\end{figure}
\footcitetext[siehe. ][Tabelle 1 S.438]{Wal84}
\newline
In der Grafik ist deutlich zu sehen, dass die Teilnehmer der Studie von Walk \& Homan beim ersten Sehen der Videos Probleme hatten, die Emotionen zu erkennen. Einzig die Emotion \textit{Wut} wurde von einem Großteil der Teilnehmer erkannt. Beim zweiten Ansehen des Videos konnten die Probanden aber deutlich besser die verschiedenen Emotionen erkennen. In diesem Fall war es für die sechs untersuchten Emotionen immer zu mindestens 70\% möglich die dargestellte Emotion zu erkennen. Im Vergleich mit der Studie von Ekman sind diese Ergebnisse schon deutlich konkurrenzfähiger. Dennoch sagen die Untersuchungsergebnisse aus, dass Probanden eher durch den Gesichtsausdruck als durch die Bewegungen eines Menschen dessen Emotionen erkennen können. Dennoch ist hier anzumerken, dass sich die Teilnehmer Anzahl der beiden Studien deutlich unterscheidet und bei dem Experiment von Ekman eine gemischte Personengruppe genutzt wurde, währenddessen Walk \& Homan ausschließlich Studenten und Studentinnen untersuchten.\newline
Dennoch zeigt das oben vorgestellte Experiment, dass eine Emotionserkennung anhand des Gangs möglich ist, und deshalb wird diese als Emotionsindiz aufgenommen.
\subsubsection{Stimme}
\subsubsectionauthor{Torben Brenner}
% Was ist die Stimme?
% Stimme als biometrisches Merkmal
Die menschliche Stimme kann ebenfalls als biometrisches Merkmal gesehen werden. Dabei ist insbesondere zu beachten, dass bei der Stimme der Faktor \textit{Permanenz} nicht gegeben ist, da diese sich im Verlaufe des Lebens ändert. Dies geschieht über Veränderungen in der Physiologie eines Menschen, zum Beispiel die Stimmbandlänge und die Kehlkopfgröße. Solche Änderungen geschehen unter anderem während dem Alterungsprozess, die stärkste davon in der Pubertät. Das Problem kann aber durch eine ständige Nachkalibrierung während jedes Identifikationsprozesses\footcite[Vgl. ][S.198 Z.22-26]{Til11} behoben werden.\newline
Patel und Scherer\footcite{Pat18} haben in ihrer Arbeit nach möglichen akustischen Merkmalen für Emotionen gesucht. Dazu haben Sie die Aussprache des Vokals ``a'' von zehn unterschiedlichen französischen Schauspielern untersucht. Die Schauspieler haben für die GEMEP Datenbank diesen Vokal jeweils in 12 unterschiedlichen emotionalen Kontexten wiedergegeben\footcite[Vgl. ][S.2 Z.13-16]{Pat18}. Dabei herausgekommen ist, dass einige dieser Merkmale sich dazu eignen, Erregung in der Stimme festzustellen\footcite[Vgl. ][S.4 Z.28-32]{Pat18}. Mit der Erregung lässt sich bereits zwischen einigen Emotionen unterscheiden, weshalb diese auch im \textit{Geneva Emotion Wheel} als eigene Dimension gewählt wurde. Aus diesem Grund ist auch die Analyse der Stimme ein für die Emotionserkennung relevanter Bereich.
\subsection{Nützliche Hardware}
In diesem Abschnitt wird die Hardware vorgestellt, die für die Messung von biometrischen Daten nützlich ist. Da die Studienarbeit sich primär mit den Möglichkeiten des Smartphones zur biometrischen Datenerfassung beschäftigt, wird das Smartphone und koppelbare Sensoren hierbei priorisiert. Außerdem wird in diesem Kapitel beschrieben, was genau unter einem Sensor verstanden wird.
\subsubsection{Smartphones}
\subsubsectionauthor{Torben Brenner}
% Definition Smartphone
Auch wenn der Begriff des Smartphones heutzutage häufig Synonym zu dem des Mobiltelefons verwendet wird, beschreiben die beiden Begriffe dennoch unterschiedliche Gerätearten. Smartphones sind im Allgemeinen eine Weiterentwicklung des herkömmlichen Mobiltelefons. Neben der Standardfunktion des mobilen Telefonierens und der Unterstützung des \textit{Short Message Service} (kurz SMS), bieten Smartphones mittlerweile viele weitere Funktionen wie zum Beispiel GPS oder Internetzugriff\footcite[Vgl. ][S.3 Z.5ff]{Bou11}.\newline
% Unterschied zum herkömmlichen Breitband Telefon/Mobiltelefonen
Dieser erhöhte Umfang an Funktionen ermöglicht es, Entwicklern Anwendungen für viele verschiedenen Anwendungsfälle bereitzustellen und somit den Nutzer deutlich besser in seinem Alltag zu unterstützen als mit einem Mobiltelefon\footcite[Vgl. ][Smartphones are tiny Computers]{Ada18}. Eine weitere Entwicklung, die vom Mobiltelefon zum Smartphone stattfand, war die Weiterentwicklung des Betriebssystems. Während Mobiltelefone meist mit simplen Betriebssystemen ausgestattet sind, werden Smartphones von komplexen Systemen wie Android oder iOS angetrieben. Diese bieten Nutzern die Möglichkeit, zusätzliche Programme zu installieren wie zum Beispiel bei Windows\footcite[Vgl. ][Mobile Operating Systems]{Ada18}.\newline
% Vergleich Leistung mit einem Computer
Der erhöhte Funktionsumfang von Smartphones im Vergleich zu Mobiltelefonen führt uns zur Frage, ob Smartphones auch dazu genutzt werden können, einen Computer zu ersetzen. Verschiedene Hersteller wie zum Beispiel Samsung mit den Dex-Stationen bieten Nutzern bereits die Möglichkeit, ihr Smartphone als PC-Ersatz zu nutzen\footcite{Kai18}. Obwohl Smartphones immer höhere Leistungsspitzen erreichen, werden sie wahrscheinlich auch in Zukunft nicht als vollständiger PC-Ersatz genutzt werden können. Das liegt insbesondere daran, dass Smartphone CPUs (Central Processing Unit) aufgrund des Formfaktors nicht so gekühlt werden können wie PC-CPUs\footcite[Vgl. ][Power and Heat]{Gav18}.\newline 
% Warum Smartphones zur Emotionserkennung? Ermöglichen Tagesanalyse/Verbreitung
Nun kommen wir zu der Frage, warum wir Smartphones verwenden wollen, um Emotionen zu erkennen. So sind Smartphones in der Lage, durch verschiedenen verbaute Sensoren zu sehen, fühlen und zu hören\footcite[Vgl.][S. 1 Abs. 2]{Bie14}. Wie in dem Artikel beschrieben, geben uns die verbauten Sensoren enorme Möglichkeiten, mit dem Smartphone die Umwelt wahrzunehmen. Wie leistungsfähig die verschiedenen Komponenten mittlerweile geworden sind, zeigt Apple mit dem IPhone X, welches mithilfe der Kamera und Infarotsensoren die Veränderungen von Gesichtszügen erkennt und auf sogenannte Animojis überträgt\footcite[Vgl. ][Animoji: So funktioniert es]{Com17}. Ein weiterer Grund, aus dem wir die Emotionserkennung mit Smartphones untersuchen wollen, ist die Tatsache, dass Smartphonenutzer ihr Gerät häufig rund um die Uhr bei sich tragen. Dies ermöglicht es für verschiedene Anwendungsszenarien, eine Überwachung der Emotionen des Nutzers über den Tag hinweg durchzuführen.
\subsubsection{Externe Sensoren}
\subsubsectionauthor{Torben Brenner \& Lukas Seemann}
Da es nicht möglich ist, alle Indizien die in Kapitel 2.4 aufgezählt wurden mithilfe der Smartphone-internen Sensoren zu erfassen, müssen zusätzliche externe Sensoren zur Erfassung von biometrischen Daten hizugezogen werden. \newline
Sensoren dienen zur Erfassung eines physikalischen Zustandes und der Transformation dieses Zustandes in einen Impuls, der verarbeitet werden kann\footcite[Vgl.][]{Web18}. In der Computertechnik dienen Sensoren häufig dazu, den physikalischen Zustand verständlich für einen Computer zu machen, indem dieser in einen Datensatz umgewandelt wird. Generell sind für einen Computer elektrische Signale erkennbar, jedoch sind nicht alle Messgrößen, die am Eingang eines Sensors anliegen, elektrisch. Die Aufgabe von Sensoren ist es also, nichtelektrische Messgrößen in ein elektrisches Signal umzuwandeln. \newline
In Abbildung 7 ist die Umsetzung dieses Vorgangs gezeigt.
\begin{figure}[h]
	\centering
	\includegraphics[width=16cm]{Bilder/sensor.png}
	\caption[Sensor als Schnittstelle zwischen nicht-elektrischen und elektrischen Raum]{Sensor als Schnittstelle zwischen nichtelektrischen und elektrischen Raum\footnotemark}
\end{figure}\footcitetext[][S. 347]{Ros13}
Ein Sensor erhält eine nichtelektrische Messgröße als Input und erfasst diese Messgröße mithilfe eines vorgelagerten Primärwandlers. Eine Primärwandler kann je nach Messgröße unterschiedlich gestaltet sein. Bei mechanischen Größen kann es zum Beispiel eine Membran oder ein Biegebalken sein, bei optischen Größen optisch abbildende Systeme wie zum Beispiel eine Linse oder eine Blende. \footcite[Vgl. ][S. 347]{Ros13} \newline \newline Das sogenannte Sensorelement stellt den eigentlichen Sensor dar, der den Übergang von nichtelektrischen in den elektrischen Raum realisiert. Hier geschieht die Umwandlung der Messgröße in ein elektrisches Signal.\footcite[Vgl. ][S. 347]{Ros13} \newline Da die Änderungen der elektrischen Größe am Ausgang des Sensorelements in der Regel sehr klein sind, muss das Signal mittels einer Primärelektronik in ein gut verarbeitbares elektrisches Signal verstärkt werden. Dazu ist häufig eine Hilfsenergie notwendig, die dem Sensor zugeführt werden muss. \footcite[Vgl. ][S. 347]{Ros13} Ist dies geschehen, kann das elektrische Signal des Sensors von Computern analysiert werden.\newline
Eine Möglichkeit, externe Sensoren mit dem Smartphone zu verbinden, ist der Einsatz von Mikrocontrollern, wie zum Beispiel ein Arduino. \footcite[Arduino UNO R3 Mikrocontroller: ][]{Ard18} Da nur wenige externe Sensoren direkt an das Smartphone angeschlossen werden können und Mikrocontroller meist sehr handlich sind, ist diese Möglichkeit sehr praktisch. Der Mikrocontroller übernimmt dann zum einen die Erfassung des elektrischen Signals des Sensors und die Übertragung der Daten zum Smartphone. 
\subsubsection{Smartphone Sensoren}
\subsubsectionauthor{Torben Brenner}
Wie bereits erwähnt, werden in Smartphones mittlerweile massenweise Sensoren verbaut, die eine Umgebungswahrnehmung möglich machen. Eine Auflistung dieser Sensoren stellt Biermann in seinem Artikel für die Zeit Online vor\footcite[siehe ][]{Bie14}.\newline
So nennt er den Beschleunigungssensor, das sogenannte Akzelerometer. Bei diesem wird mithilfe eines kleinen Siliziumstabs und einer Elektrode die Beschleunigung gemessen. Diese Konstruktion wird dreimal verwendet, um für die x-,y- und z-Achse eine Beschleunigungsbestimmung durchführen zu können.\newline
Das Gyroskop ist ein weiterer Sensor, der in Smartphones Platz findet. Dieser dient dazu, mit Hilfe von in Schwingung versetzten Metallelementen und Kondensatoren zu prüfen, ob das Handy hoch oder quer gehalten wird.\newline
Das sogenannte Magnetometer misst auf der X-, Y- und Z-Achse die Stärke und Richtung des Erdmagnetfeldes. Laut Biermann ist zum Beispiel im iPhone 4 ein solcher Sensor verbaut. Dieser kann unter anderem dazu genutzt werden, Stromleitungen in einer Wand zu finden.\newline
Der Touchscreen selbst ist ebenfalls ein Sensor. Dieser besteht aus zwei Gittern, zwischen denen ständig Stromsignale ausgetauscht werden. Dabei wird von der oberen Schicht ein Impuls an die untere Schicht gesendet. Durch Berührung mit dem Finger, und dessen Feuchtigkeit, wird das Signal lokal schwächer. Diese Veränderung wird von einem Prozessor zur Position des Fingers umgerechnet.\newline
Dies war nur eine kleine Auswahl aller Sensoren, die in Smartphones verbaut sind. Neben den genannten Sensoren werden zum Beispiel auch die Kamera und das Mikrofon als Sensoren verstanden. Diese werden aber in späteren Kapiteln noch einmal genauer beschrieben.
\subsection{Möglichkeiten der Erfassung von biometrischen Daten} 
\subsectionauthorlong{Torben Brenner}
In diesem Abschnitt werden unterschiedliche Möglichkeiten vorgestellt, die in \ref{section:Emotionsindizien} vorgestellten Emotionsindizien zu erfassen. Da es nicht immer nur eine Möglichkeit gibt, diese zu erfassen, werden hier verschiedene Methoden vorgestellt. Basierend auf den Ergebnissen dieses Abschnitts wird im späteren Verlauf eine Priorisierung vorgenommen.  
\subsubsection{GSR-/EDA-Sensoren}
\subsubsectionauthor{Lukas Seemann}
Die bereits in Kapitel 2.4.2 beschriebene elektrodermale Aktivität kann mithilfe von EDA-Sensoren gemessen werden. Diese Art von Sensoren sind üblicherweise nicht in Smartphones eingebaut, weswegen die Hautleitfähigkeit mit externer Hardware gemessen werden muss. \newline
\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{Bilder/gsr-hand.jpg}
	\caption[Positionsmöglichkeiten der EDA-Messung]{Positionsmöglichkeiten der EDA-Messung\footnotemark}
\end{figure}\footcitetext[][Folie 25]{Sch12}
\newline
Die für heute eher unübliche Messungsart der elektrodermalen Aktivität stellt die endosomatische Messung dar. Indem winzige Elektroden in die Haut eingestochen werden, kann die Aktivität der Nerven in der Haut gemessen werden. \footcite[Vgl.][Folie 25]{Sch12} Hierbei handelt es sich jedoch nicht um eine Messung der Hautleitfähigkeit sondern um eine Messung des Hautpotenzials. \newline
Bei der exosomatischen Messung hingegen wird ein schwacher Strom von ungefähr 0.5 Volt an die Haut angelegt. Die Spannung wird hierbei konstant gehalten, wodurch die Leitfähigkeit oder der Widerstand der Haut gemessen werden kann. Die hierbei verwendeten Einheiten sind entweder Siemens für den elektrischen Leitwert oder Ohm für den Widerstand. Die Elektroden des Sensor sind meistens aus Silber oder Silberchlorid und werden meist an zwei Stellen der nicht dominanten Hand angebracht. \footcite[Vgl.][Folie 25]{Sch12} Wie in Abbildun<g 8 dargestellt gibt es verschiedenen Möglichkeiten der Handinnenfläche, die gut geeignet sind, (\#1, \#2 oder \#3). \newline
Diese Art von Sensoren sind die heutzutage übliche Vorgehensweise bei EDA-Messungen. Häufig sind sie auch unter dem Namen GSR-Sensor\footnote{GSR: Galvanic Skin Response} bekannt und darunter im Internet erhältlich. GSR-Sensoren sind als Modul für den Mikrocontroller Arduino verfügbar.\footcite[beispielsweise:][]{Gro18} Dies stellt eine Möglichkeit dar, einem mobilen Endgerät die Sensordaten zum Beispiel über Bluetooth oder WiFi zur Verfügung zu stellen. In Abbildung 9 ist ein GSR-Sensor inklusive der Elektroden für die Fingerinnenseiten, der mit Arduinos kompatibel ist, abgebildet.
\begin{figure}[h]
	\centering
	\includegraphics[width=16cm]{Bilder/sensor.jpg}
	\caption[GSR-Sensor mit Finger-Elektroden]{GSR-Sensor mit Finger-Elektroden\footnotemark}
\end{figure}%
\footcitetext{Gro18}
\newline \newline \newline \newline
\subsubsection{Stimmerkennung mit Smartphone-Mikrofon}
\subsubsectionauthor{Torben Brenner}
Grundsätzlich haben alle Smartphones ein Mikrofon, da dieses insbesondere für das Telefonieren gebraucht wird. Biermann schreibt in seinem Artikel außerdem davon, dass heutige Smartphones nicht nur ein Mikrofon, sondern gleich mehrere Mikrofone besitzen. Die zusätzlichen Mikrofone werden unter anderem dazu verwendet, Störgeräusche herauszufiltern\footcite[Vgl. ][S.2 Mikrofon Abs.2]{Bie14}.\newline
Dass die Stimmerkennung sich im Allgemeinen immer weiterentwickelt, zeigen so genannte \textit{Vocal Computing} Schnittstellen. Dieser Begriff bezeichnet laut Ferdinand und Jetzke ``die Möglichkeit, über Sprache mit Computern, mobilen und stationären Endgeräten sowie deren softwarebasierten Anwendungen zu interargieren''\footcite[siehe ][S.1 Z.1ff]{Fer17}. War es früher noch schwer möglich einzelne Wörter zu erkennen, gibt es mittlerweile Smartphone Anwendungen wie Apples ``Siri'' und Googles ``Google Now'', ``die nicht auf einzelne Befehle reduziert [sind], sondern ganze Sätze und den Kontext ihrer Äußerung erfassen [können]''\footcite[siehe ][S.1 Z.17ff]{Fer17}.\newline
Dass auch in der Emotionserkennung über die Stimme ein Fortschritt erreicht wurde, zeigen russische Forscher mit einem KI-Algorithmus\footcite[Vgl. ][]{Sta17}. Der Algorithmus versucht im Allgemeinen, zwischen acht verschiedenen Basisemotionen zu unterscheiden. Dabei scheint es insbesondere bei der Unterscheidung zwischen Freude und Ärger Probleme zu haben. Diese zeichnen sich beide durch eine starke Erregung aus. Wie bereits bei der Beschreibung der Stimme als Emotionsindiz erwähnt, ist dies eines der Hauptmerkmale, die sich über die Stimme erfassen lassen.\newline
Dass sich solche Anwendungen auch in Form einer Smartphone App umsetzen lassen, haben Ingeneure der University of Rochester gezeigt\footcite[Vgl. ][]{Wed12}. Diese untersuchen in ihrem Programm zwölf unterschiedliche Charakteristiken in gesprochenen Worten, um so zwischen sechs unterschiedlichen Emotionen unterscheiden zu können. Ein App Prototyp zeigt anscheinend schon je nach Stimme einen traurigen oder fröhlichen Smiley an.
\subsubsection{Gesichtserkennung mit Smartphone-Kamera}
\subsubsectionauthor{Torben Brenner}
Zur Erfassung der Mimik benötigt das Smartphone die Fähigkeit, ein Gesicht und den Gesichtsausdruck zu erfassen. Hierfür eignet sich  die Kamera des Smartphones. Diese war früher ausschließlich für das Aufnehmen von Bildern gedacht. Mittlerweile werden aber die in Smartphones verbauten Kameras immer besser und können unter anderem für die Gesichtserkennung oder die Verfolgung der Augenbewegungen genutzt werden\footcite[Vgl. ][Seite 2 Kamera Abs. 1+2]{Bie14}.\newline % Warum eignet sich die Handykamera?
Canzler\footcite{Can01} beschreibt in seiner Arbeit ein Verfahren, um mit Kameras die menschliche Mimik automatisiert zu analysieren. Basierend auf seinen Methoden kann ein System entwickelt werden, das aus der Mimik eines Menschen dessen Emotionen analysiert. Canzler beschreibt in seiner Arbeit folgende vier Phasen der Analyse\footcite[Vgl. ][S.2-5]{Can01}:
\begin{itemize}
	\item[1.] \textbf{Gesichtsdetektion}
	\item[2.] \textbf{Tracken charakteristischer Punkte}
	\item[3.] \textbf{Extraktion von Mermalen}%in publikation Mermalen
	\item[4.] \textbf{Gesichtsanalyse}
\end{itemize}
Die vier von Canzler ausgearbeiteten Phasen können bis auf wenige Anpassungen übernommen werden. Die Gesichtsdetektion wird mit Hilfe von verschiedenen Verfahren durchgeführt. Die formorientierten Verfahren suchen nach Kanten und Konturen, welche dem menschlichen Gesicht entsprechen und farborientierten Verfahren, die nach charakteristischen menschlichen Hautfarben suchen\footcite[Vgl. ][S.2 Z.14ff]{Can01}. In der zweiten Phase wird anhand eines vordefinierten durchschnittlichen Gesichts eine Verfolgung von wichtigen Punkten durchgeführt. % Hier wäre es cool über den susan edge kantendetektor zu 
Basierend auf den geometrischen Eigenschaften des Gesichts können daraufhin mit Template Matching verschiedene Merkmale, wie zum Beispiel die Blickrichtung und Stirnfaltenbildung, extrahiert werden. In der letzten Phase, der Gesichtsanalyse, werden die vorher ermittelten Merkmale in sogenannte \textit{Action Units} umgesetzt\footcite[Vgl. ][S.4 Z.17-21]{Can01}. Diese wurden im \textit{Facial Action Coding System} definiert. Sie beschreiben die kleinsten sichtbaren Einheiten von Muskulatur im Gesicht\footcite[Vgl. ][S.94 Z.9ff]{Kai98}. Die Action Units wurden bereits von verschiedenen Forschern in Zusammenhang mit den Emotionen gebracht. Problematisch ist aber laut Kaiser\footcite{Kai98}, dass vollständig vordefinierte Gesichtsausdrücke selten genauso in der Realität vorkommen, weshalb es sinnvoller ist den Zusammenhang zwischen einzelnen AUs und bestimmten Emotionen zu untersuchen\footcite[Vgl. ][S.94 Z.16-30]{Kai98}. Kaiser \& Scherer haben in ihrer Arbeit zum Beispiel das Auftreten verschiedener AUs in Zusammenhang mit emotionalen Störungen wie Depressionen beschrieben\footcite[Vgl. ][S.95 Table 6.3 Facial Action Units Predicted as Indicators of Selected Types of Affect Disorders]{Kai98}.
Es gibt bereits mehrere Systeme, die es ermöglichen, mit der Analyse des Gesichtsemotionen zu bestimmen. So gibt es vom Frauenhofer-Institut für Integrierte Schaltungen das SHORE System\footcite[Vgl. ][]{Fra18}. Dieses ermöglicht, die Gesichtsanalyse ohne Internetanbindung. Dabei lassen sich sowohl das Geschlecht und Alter, als auch vier unterschiedliche Emotionen erkennen. Es soll außerdem auch auf mobilen Endgeräten funktionieren. Es gibt eine kostenlose Demo, die aber auf eine Laufzeit von 90 Tagen beschränkt ist, weshalb sie sich für unsere Zwecke nicht eignet\footcite[Vgl. ][]{Fra18b}.\newline
Da Smartphones sich unter anderem durch die Möglichkeit auszeichnen, sich unterwegs mit dem Internet zu verbinden, ist auch die Nutzung einer Server Anwendung denkbar. Microsoft bietet zum Beispiel eine Schnittstelle für die Gesichtserkennung\footcite[Vgl. ][]{Mic18}. Diese bietet nicht nur die Möglichkeit, Personen zu erkennen und deren Alter zu bestimmen, sondern ermöglicht es auch, die Emotionen einer Person zu schätzen. Die kostenlose Nutzung erlaubt 30.000 Transaktionen im Monat mit bis zu 20 Transaktionen in der Minute\footcite[Vgl. ][]{Mic18b}.
\subsubsection{Pulsmessung mit Smartphone-Kamera}
\subsubsectionauthor{Lukas Seemann}
In den App-Stores werden heutzutage mehrere Apps angeboten, die angeben, eine Pulsmessung ohne zusätzliche Geräte zu ermöglichen. \footcite[Vorstellung von Pulsmessungs-Apps auf dem Markt: Vgl.][]{Pet17} Diese Apps nutzen lediglich die im Smartphone integrierte Kamera. Das Ergebnis wird deutlich genauer, wenn das Smartphone außerdem über ein LED-Blitzlicht verfügt.\footcite[Vgl.][]{Gil14} \newline
Die Vorgehensweise bei dieser Art der Pulsmessung ist nicht komplex. Der Smartphone-Nutzer muss dazu lediglich die oberste Fingerkuppe eines beliebigen Fingers auf die Kamera und falls vorhanden auch auf das Blitzlicht des Smartphones legen. Ist kein Blitzlicht vorhanden, ist es auch möglich, die Messung bei gutem Tageslicht durchzuführen.\footcite[Vgl.][]{Gil14} Dies kann jedoch Auswirkungen auf die Genauigkeit des Ergebnisses haben. Über ein gewissen Zeitraum, der meistens im Sekunden- oder niedrigen Minutenbereich liegt, werden anschließend die Helligkeitsschwankungen in der Fingerkuppe des Nutzer aufgezeichnet.\footcite[Vgl.][]{Pre16} Diese Helligkeitschwankungen werden durch den Puls des Benutzer ausgelöst, da der Finger bei hoher Durchblutung nicht so lichtdurchlässig ist, wie bei niedriger Durchblutung. Aus diesen dokumentierten Schwankungen berechnen die Apps mithilfe von signalanalytischen Methoden den Puls des Benutzers. \footcite[Vgl.][]{Pre16} \newline
Diese Methoden sind bereits teilweise laut App-Hersteller-Angaben medizinisch anerkannt\footcite[Vgl.][]{Pre16} und liefern unter guten Bedingung dieselben Ergebnisse, die auch herkömmliche Blutdruckmessgeräte ermittlen würden.\footcite[Vgl.][]{Hen17}
Dieses Verfahren der Pulsmessung basiert auf der Pulsoxymetrie. Das Ziel der Pulsoxymetrie ist es, mithilfe von Lichtquellen die Sauerstoffsättigung und die Pulswelle des Probanden zu messen. \footcite[Vgl. ][S. 74]{Deu09} Als Messorte eignen sich hierfür die Ohren, Zehen oder die Finger, was bei der Smartphone-Messung ausgenutzt wurde. \newline 
\glqq \textit{Bei der Pulsoxymetrie werden von einer Lichtquelle 2 unterschiedliche Wellenlängen (im infraroten und roten Bereich) ausgesendet, die nach dem Durchleuchten des Gewebes (z.B. am Finger) von einem Sensor aufgefangen werden.}\grqq{ \footcite[][S. 74]{Deu09} Neben der hierbei durchgeführten Messung der Sauerstoffsättigung kann durch die Absorption des Lichts durch die Fingerkuppe über die insgesamt aufgefangene Lichtmenge eine Aussage über die Pulswelle des Probanden abgeleitet werden. \footcite[Vgl. ][S. 74]{Deu09} Obwohl die meisten Smartphones keine verschiedenen Lichtwellenlängen verwenden, sind bereits die Messungen mit dem Blitzlicht des Smartphones für den Puls sehr aussagekräftig. Die unterschiedlichen Lichtwellenlängen sind vor allem für die Sauerstoffsätigung notwendig, deren Messung die meisten Apps nicht anbieten. \newline \newline
Des Weiteren gibt es noch eine Möglichkeit, wie die Smartphone-Kamera zur Pulsbestimmung genutzt werden kann. Mithilfe der Eulerschen Videoverstärkung (\textit{Eulerian Video Magnification}, kurz EVM), die am Massachusetts Institute of Technology (MIT) von einer Gruppe von Informatikern entwickelt wurde, können kleinste Bewegungen in Videomaterial verdeutlicht werden. \footcite[Vgl. ][]{Dam12} Mit einer Videoaufnahme des Gesichts eines Probanden kann so der Puls mit einer hohen Genauigkeit bestimmt werden. Durch die pulsierende Blutzirkulation ändert sich die Gesichtfarbe einer Person ungefähr einmal pro Sekunde. Dies ist mit bloßem Auge nicht sichtbar, kann jedoch mit Hilfe von EVM verstärkt und somit deutlich sichtbar gemacht werden. Mithilfe dieser Farbtonschwankungen kann der Puls sogar in Echtzeit bestimmt werden. \footcite[Vgl. ][]{Dam12} \newline
\begin{figure}[h]
	\centering
	\includegraphics[width=16cm]{Bilder/evm.jpg}
	\caption[Eulersche Videoverstärkung zur Pulsbestimmung]{Positionsmöglichkeiten der EDA-Messung\footnotemark}
\end{figure}\footcitetext{MIT15} \newline
In Abbildung 10 ist die Vorgehensweise bei der Pulsbestimmung gezeigt. Zunächst wird das aufgenommene Videomaterial in einzelne Frames unterteilt (siehe \textit{(a)}). Die einzelnen Frames werden dann mithilfe von EVM verstärkt, sodass die durch die Durchblutung veränderte Gesichtfarbe deutlich wird (siehe \textit{(b)}). Rot deutet dabei auf eine hohe Durchblutung hin, wohingegen eine blasse Farbe eine niedrige Durchblutung bedeutet. In \textit{(c)} wird anschließend ein Graph angefertigt, der Ausschnitte des Gesichts im Verlauf der Zeit anzeigt. Bei nicht verstärktem Input sind keine Unterschiede sichtbar. Mit EVM kann jedoch deutlich ausgemacht werden, wie sich die Gesichtsfarbe im Verlauf der Zeit geändert hat. Auf Basis dieses Graphen kann anschließend der Puls bestimmt werden. \footcite[Vgl.][]{MIT15} \newline
Da Smartphones heutzutage über sehr gute Kameras verfügen, kann die Nutzung von EVM eine gute Möglichkeit zur Pulsbestimmung darstellen.
\subsubsection{Pulsmessung mit externen Sensoren}
\subsubsectionauthor{Lukas Seemann}
Neben der Pulsmessung über die Smartphone-Kamera gibt es auch die Möglichkeit, mit externen Sensoren den Puls zu messen. Hierbei gibt es auch passende Module, die an einen Arduino-Mikrocontroller angeschlossen werden können. \newline
In Abbildung 11 ist ein häufig verwendeter Puls-Sensor des Unternehmens World Famous Electronics llc. zu sehen, der mit einem Arduino verbunden werden kann. \newline
\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{Bilder/pulsesensor.jpg}
	\caption[Puls-Sensor für einen Arduino]{Puls-Sensor für einen Arduino\footnotemark}
\end{figure}\footcitetext{Wor18a}
Dieser Sensor kann entweder am Finger oder am Ohr des Probanden angebracht werden. Das Messverfahren basiert hierbei ebenfalls auf der Pulsoxymetrie, es handelt sich also um einen optischen Sensor. Bei Sensor handelt es sich um einen Photoplethysmograph (kurz PPG), der auf dieser Art und Weise häufig für medizinische Untersuchungen eingesetzt wird. \footcite[Vgl. ][]{Wor18b}
Einen PPG macht aus, dass ein zu untersuchendes Hautareal mit Infrarotlicht ausgesetzt wird und anschließend untersucht wird, wie viel Licht vom Areal absorbiert wurde. \footcite[Vgl. ][S. 38]{Rab06}
Dies ist auch der Unterschied zur Smartphone-Kamera, bei der nur das Blitzlicht beziehungsweise das Tageslicht zur Messung und kein Infrarotlicht verwendet wird.
\subsubsection{Analyse des Tippverhaltens bei Smartphone-Nutzung}
\subsubsectionauthorlong{Torben Brenner}
Grundsätzlich benötigt man bei der Tippverhaltensanalyse keine zusätzliche Hardware, da sich Aspekte wie der Tipprhythmus, die Tippgeschwindigkeit und Tippfehler Softwareseitig analysieren lassen. Hierzu wird aber der Zugriff auf eingegebene Texte benötigt, weshalb es grundsätzlich nicht möglich ist, auf einem Smartphone diese Daten zu erhalten. Das liegt daran, dass der Nutzer vor dem Mitlesen seiner Passwörter geschützt werden soll. Dass es dennoch möglich ist, auf dem Smartphone Informationen über das Tippverhalten eines Nutzers auszulesen, zeigt die schwedische Firma Behaviosec. Diese Firma hat eine Software entwickelt, die bei der Eingabe einer PIN oder eines Passwortes die Tippgeschwindigkeit, die aufliegende Fläche der Fingerkuppe oder den Winkel prüft, in dem das Smartphone gehalten wird\footcite[Vgl. ][]{Hub14}.\newline \newline \newline
\subsubsection{Gangerkennung mit dem Smartphone}
\subsubsectionauthor{Torben Brenner}
Zur Ermittlung der Gangart gibt es mehrere Methoden, um diese umzusetzen. Im Folgenden sollen diese Methoden vorgestellt und geprüft werden, ob diese mit einem Smartphone umsetzbar sind.\newline
Eine bereits in der Praxis auch eingesetzte Methode ist die Verwendung von speziellen, mit Sensoren ausgestatteten Bodenplatten\footcite[Vgl. ][Praktische Anwendung]{Bio18}. Jansen und andere Forscher\footcite{Jan06} untersuchten in ihrer Arbeit die Möglichkeit, mit solchen Bodenplatten auch Rückschlüsse auf Emotionen zu ermöglichen. Sie kommen zu dem Schluss, dass mit der Erkennung durch Bodenplatten es zumindest möglich ist, zwischen einzelnen Emotionen wie Trauer und Wut zu unterscheiden\footcite[Vgl. ][S.4 Diskussion]{Jan06}. Um diese Möglichkeit aber mit dem Smartphone umzusetzen, müsste das Smartphone mit diesen Sensoren verbunden werden, zum Beispiel über Bluetooth oder NFC (Near Field Communication).\newline
Dies ist aber nicht die einzige Möglichkeit den Gang zu erkennen. So kann laut Claudia Nickel zum Beispiel auch videobasiert eine Gangerkennung durchgeführt werden\footcite[Vgl. ][S.281 Z.9-15]{Cla09}. Diese wäre grundsätzlich auch mit dem Smartphone möglich, würde aber das dauerhafte Aufnehmen eines Videos voraussetzen. Außerdem müsste in diesem Video eine Person dauerhaft erkennbar sein, was bei der normalen Bedienung eines Smartphones nicht ohne weiteres möglich ist. Deshalb stellt Nickel noch eine dritte Variante der Gangerkennung vor, nämlich die Erkennung anhand eines Beschleunigungssensors. Diese Variante eignet sich laut Nickel besonders gut für die Erkennung in mobilen Geräten, vor allem da diese Art von Sensor in den meisten Geräten verbaut ist\footcite[Vgl. ][S.281 Z.25-36]{Cla09}. In ihrer Dissertation beschäftigt sich Nickel insbesondere mit der Gangerkennung durch diesen Sensor.